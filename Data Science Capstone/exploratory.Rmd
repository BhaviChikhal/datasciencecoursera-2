---
title: "Capstone Swiftkey Exploratory Analysis"
output: html_document
---

This is just some quick exploratory analysis done on the training data provided. Anyways, the english data is first loaded.

```{r}
#Packages
library(ggplot2)

#Data
dir = 'input/en_US/'
train_blogs = readLines(paste0(dir,"en_US.blogs.txt"))
train_twitter = readLines(paste0(dir,"en_US.twitter.txt"))
con = file(paste0(dir,"en_US.news.txt"), open="rb")
train_news = readLines(con, encoding="UTF-8")
close(con)
```


```{r}
data.frame(dataset=c("train_blogs", "train_news", "train_twitter"), num_lines=(c(length(train_blogs), length(train_news),length(train_twitter))), max_length=c(nchar(train_blogs[which.max(nchar(train_blogs))]), nchar(train_news[which.max(nchar(train_news))]), nchar(train_twitter[which.max(nchar(train_twitter))])))
```
As can be seen in this data frame, twitter seems to have the largest number of elements compared to the other datasets. Blogs has the longest length followed by news. The longest tweet is a bit under the 213 which is odd considering the max length of 140. The data will be subsetted for training data.

```{r}
#Takes sampling of each data
train_blogs = sample(train_blogs, 300000)
train_news = sample(train_news, 300000)
train_twitter = sample(train_twitter, 300000)
```