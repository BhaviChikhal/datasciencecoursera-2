ordered= dm[order(dm$freq, decreasing=TRUE),]
ordered = ordered[1:20]
ordered[1:20]
ordered[1:20,]
ordered = ordered[1:20,]
ggplot(ordered, aes(x=word, y=freq)) + geom_histogram(stat="identity")
??labeller
??label
ordered= dm[order(dm$freq, decreasing=TRUE),]
ordered = ordered[1:10,]
ggplot(ordered, aes(x=word, y=freq)) + geom_histogram(stat="identity")
word_freqs = sort(colSums(ngram1), decreasing=TRUE)
dm = data.frame(word=names(word_freqs), freq=word_freqs)
ordered= dm[order(dm$freq, decreasing=TRUE),]
ordered = ordered[1:10,]
ggplot(ordered, aes(x=word, y=freq)) + geom_histogram(stat="identity") + labs(title="Top 10 1gram")
m = as.matrix(ngram2)
word_freqs = sort(rowSums(m), decreasing=TRUE)
dm = data.frame(word=names(word_freqs), freq=word_freqs)
ordered= dm[order(dm$freq, decreasing=TRUE),]
ordered = ordered[1:10,]
ggplot(ordered, aes(x=word, y=freq)) + geom_histogram(stat="identity") + labs(title="Top 10 2gram")
#Load Packages
library(tm)
library(RWeka)
#Load Data
dir = 'input/en_US/'
train_blogs = readLines(paste0(dir,"en_US.blogs.txt"))
train_twitter = readLines(paste0(dir,"en_US.twitter.txt"))
con = file(paste0(dir,"en_US.news.txt"), open="rb")
train_news = readLines(con, encoding="UTF-8")
close(con)
#Subset data for memory issues
set.seed(100)
train_blogs = sample(train_blogs, 500000)
train_news = sample(train_news, 500000)
train_twitter = sample(train_twitter, 500000)
#Create a corpus from dataset
create_corpus = function(dm){
corpus = Corpus(VectorSource(dm))
corpus = tm_map(corpus, removeNumbers) # remove numbers
corpus = tm_map(corpus, stripWhitespace) # remove whitespaces
corpus = tm_map(corpus, tolower) #lowercase all contents
corpus = tm_map(corpus, removePunctuation) # remove punctuation
corpus = tm_map(corpus, removeWords, c("fuck", "bitch", "ass", "cunt", "pussy", "asshole", "douche")) #remove some swears
corpus = tm_map(corpus, PlainTextDocument) #convert to plaintextdocument
return(corpus)
}
#Setup corpus from training data
train_words = c(train_blogs, train_news, train_twitter)
train_corpus = create_corpus(train_words)
#Create 1gram
ngram1 = DocumentTermMatrix(train_corpus)
ngram1 = removeSparseTerms(ngram1, 0.995) #keep words in that appear in 99.5%
ngram1 = as.data.frame(as.matrix(ngram1))
#Create 2-grams
create_n2 = function(corpus){
TwogramTokenizer = function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
ngram2 = TermDocumentMatrix(corpus, control = list(tokenize = TwogramTokenizer))
ngram2 = removeSparseTerms(ngram2, 0.995)
ngram2 = as.data.frame(as.matrix(ngram2))
return(ngram2)
}
ngram2 = create_n2(train_corpus)
#Load Packages
library(tm)
library(RWeka)
#Load Data
dir = 'input/en_US/'
train_blogs = readLines(paste0(dir,"en_US.blogs.txt"))
train_twitter = readLines(paste0(dir,"en_US.twitter.txt"))
con = file(paste0(dir,"en_US.news.txt"), open="rb")
train_news = readLines(con, encoding="UTF-8")
close(con)
#Sample data size due to memory issues
set.seed(100)
train_blogs = sample(train_blogs, 200000)
train_news = sample(train_news, 200000)
train_twitter = sample(train_twitter, 200000)
#Create a corpus from dataset
create_corpus = function(dm){
corpus = Corpus(VectorSource(dm))
corpus = tm_map(corpus, removeNumbers) # remove numbers
corpus = tm_map(corpus, stripWhitespace) # remove whitespaces
corpus = tm_map(corpus, tolower) #lowercase all contents
corpus = tm_map(corpus, removePunctuation) # remove punctuation
corpus = tm_map(corpus, removeWords, c("fuck", "bitch", "ass", "cunt", "pussy", "asshole", "douche")) #remove some swears
corpus = tm_map(corpus, PlainTextDocument) #convert to plaintextdocument
return(corpus)
}
#Setup corpus from training data
train_words = c(train_blogs, train_news, train_twitter)
train_corpus = create_corpus(train_words)
#Create 1gram
ngram1 = DocumentTermMatrix(train_corpus)
ngram1 = removeSparseTerms(ngram1, 0.995) #keep words in that appear in 99.5%
ngram1 = as.data.frame(as.matrix(ngram1))
save.image("~/GitHub/datasciencecoursera/Data Science Capstone/ng.RData")
#Create 2-grams
create_n2 = function(corpus){
TwogramTokenizer = function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
ngram2 = TermDocumentMatrix(corpus, control = list(tokenize = TwogramTokenizer))
ngram2 = removeSparseTerms(ngram2, 0.995)
ngram2 = as.data.frame(as.matrix(ngram2))
return(ngram2)
}
ngram2 = create_n2(train_corpus)
#Create 2-grams
create_n2 = function(corpus){
TwogramTokenizer = function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
ngram2 = TermDocumentMatrix(corpus, control = list(tokenize = TwogramTokenizer))
ngram2 = removeSparseTerms(ngram2, 0.995)
ngram2 = as.data.frame(as.matrix(ngram2))
return(ngram2)
}
ngram2 = create_n2(train_corpus)
save.image("~/GitHub/datasciencecoursera/Data Science Capstone/ng.RData")
head(ngram2)
View(ngram2)
#Create 3-grams
create_n3 = function(corpus){
TrigramTokenizer = function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3))
ngram3 = TermDocumentMatrix(corpus, control = list(tokenize = TrigramTokenizer))
ngram3 = removeSparseTerms(ngram3, 0.999)
ngram3 = as.data.frame(as.matrix(ngram3))
return(ngram3)
}
ngram3 = create_n3(train_corpus)
View(ngram3)
save.image("~/GitHub/datasciencecoursera/Data Science Capstone/ng3.RData")
View(ngram3)
View(ngram3)
head(colSums(ngram1))
test = colSums(ngram1)
is.data.frame(test)
test = as.data.frame(test)
test
head(test)
rowSums(ngram1)
test = colSums(ngram1)
test\
test
names(ngram1)
test$words = names(ngram1)
test
test  = colSums(ngram1)
test  = as.data.frame(test)
test
test[1]
?colSums
test = colSums(ngram1)
test = colSums(ngram1, dims=2)
test = colSums(ngram1)
test[1]
test[2]
test[3]
test[4]
test[5]
test[6]
str(test)
test$names
names(test)
names(test)
test[[1]]
test[[]]
test[[,]]
test[[:]]
length(test[[]])
length(test[[1:length(test)]])
length(test)
test[[1:length(test)]]
test[[1:length(test),]]
test[[,1:length(test)]]
test[[525]]
test[[1:525]]
test[[1:2]]
test[[2]]
test[[1]]
test[[2]]
test[[]]
test[
]
test[1[]]
test[2[]]
test[,[]]
test[,
]
colSums(ngram1, dims=525)
dims(ngram1)
dim(ngram1)
colSums(ngram1, dims=600000)
colSums(ngram2)
rowSums(ngram2)
raw_ngram1 = colSums(ngram1)
rm(test)
rm(raw_ngram1)
ngram1_total = colSums(ngram1)
ngram1_total
ngram1_raw = as.data.frame(ngram1_total)
ngram1_raw
ngram1_raw$words = names(ngram1)
head(ngram1_raw)
as.numeric(ngram1_raw)
ngram1_total[1:525[1]]
ngram1_total[1:525,[1]]
ngram1_total[1:525[1],]
ngram1_total[1:525[2]]
ngram1_total[1:525[0]]
ngram1_total[1:525[1]]
ngram1_total[1[1]]
ngram1_total[1[2]]
ngram1_total[1[1]]
ngram1_total[1[]]
ngram1_total[[]]
ngram1_total[[1]]
ngram1_total[[2]]
ngram1_total[[3]]
ngram1_total[[4]]
ngram1_total[[5]]
ngram1_total[[1:2]]
ngram1_total[[c(1:525)]]
unlist(ngram1_total)
?unlist
test = unlist(ngram1_total)
test
test[1]
test[[1]]
test[[1:1]]
test[[1:2]]
test[[1,2]]
test[1,2]
test[1]
test[1][1]
test[1][2]
test[1][3]
test[1][0]
as.nuermic(test[1])
as.numeric(test[1])
as.numeric(test[1:525])
ngram1_raw$total = as.numeric(ngram1_total[1:length(ngram1_total)])
ngram1_raw$total
ngram1_raw
names(ngram1_raw)
ngram1_raw$ngram1_total = NULL
head(ngram1_raw)
ngram1_raw = data.matrix(matrix(2,525))
?data.matrix
?matrix
ngram1_raw = data.matrix(matrix(nrow=2,ncol=525))
ngram1_raw
ngram1_raw = data.matrix(matrix(nrow=525,ncol=2))
ngram1_raw = data.matrix(matrix(nrow=525,ncol=2), dimnames=c("words", "counts"))
ngram1_raw = data.matrix(matrix(nrow=525,ncol=2))
ngram1_raw = data.matrix(matrix(nrow=525,ncol=2))
ngram1_raw$words = names(ngram1)
ngram1_raw
names(ngram1)
names(ngram1_raw)
ngram1_raw = data.matrix(matrix(nrow=525,ncol=2))
ngram1_raw$total = as.numeric(colSums(ngram1)[1:525])
ngram1_raw
ngram1_raw[1]
ngram1_raw[2]
ngram1_raw[3]
ngram1_total = colSums(ngram1)
ngram1_total = colSums(ngram1)
ngram1_raw = data.matrix(as.numeric(ngram1_total[1:525]))
ngram1_raw
names(ngram1_raw) = "total"
ngram1_raw$words = names(ngram1)
ngram1_raw
ngram1_total = colSums(ngram1)
ngram1_raw = data.matrix(as.numeric(ngram1_total[1:525]))
names(ngram1_raw) = "total"
ngram1_raw$words = as.data.frame(names(ngram1))
ngram1_raw = data.matrix(as.numeric(ngram1_total[1:525]))
names(ngram1_raw) = "total"
ngram1_raw[1]
ngram1_raw[2]
ngram1_raw[3]
ngram1_raw[4]
ngram1_raw
ngram1_raw = as.numeric(ngram1_total[1:525])
ngram1_raw
ngram1_raw = data.table(ngram1_raw, names(ngram1))
ngram1_raw = data.frame(ngram1_raw, names(ngram1))
ngram1_raw
head(ngram1_raw)
ngram1_raw = data.frame(names(ngram1),ngram1_raw)
ngram1_raw = as.numeric(ngram1_total[1:525])
ngram1_raw = data.frame(names(ngram1),ngram1_raw)
#Process raw ngrams
ngram1_total = colSums(ngram1)
ngram1_raw = as.numeric(ngram1_total[1:525])
ngram1_raw = data.frame(names(ngram1),ngram1_raw)
names(ngram1_raw) = c("words", "total")
head(ngram1_raw)
ngram2_total = rowSums(ngram2)
ngram2_total
ngram2_total[1]
as.numeric(ngram2_total[1])
length(ngram2)
nrow(ngram2)
ngram2_raw = as.numeric(ngram2_total[1:nrow(ngram2)])
ngram2_raw = data.frame(names(ngram2),ngram2_raw)
names(ngram2_raw) = c("words", "total")
names(ngram2)
View(ngram2)
as.character(ngram2_total[1])
as.character(ngram2_total[2])
as.character(ngram2_total[{1}])
as.character(ngram2_total[[1]])
as.character(ngram2_total[[2]])
ngram2_total[1]
ngram2_total[2]
ngram2_total[3]
ngram2_raw = as.numeric(ngram2_total[1:nrow(ngram2)])
ngram2_raw
names(ngram2[1:22])
names(ngram2[1:220)
names(ngram2[1:220])
ngram2_total
ngram2_total[1]
ngram2_total[1[]]
ngram2_total[2[]]
ngram2_total[1[1]]
ngram2_total[1[2]]
ngram2_total[[]]
ngram2_total[[1]]
ngram2_total[[0]]
ngram2_total[1
]
test = as.array(ngram2_total)
test
test[1]
test[[1]]
test[[0]]
test
test[1,2]
test[1,1]
test[0,1]
test[0]
test[1]
test = as.data.frame(ngram2_total)
test[1]
test[1,2]
test[1[1]]
test[1[1]]
test[1[[]]]
test[1[[1]]]
test[1[[2]]]
ngram2_total
is.list(ngram2_total)
str(ngram2_total)
names(ngram2_total)
names(ngram2_total)[1]
ngram2_raw = as.numeric(ngram2_total[1:nrow(ngram2)])
ngram2_raw = data.frame(names(ngram2_raw),ngram2_raw)
names(ngram2_raw) = c("words", "total")
names(ngram2_raw)
ngram2_raw = as.numeric(ngram2_total[1:nrow(ngram2)])
ngram2_raw = data.frame(names(ngram2_total),ngram2_raw)
names(ngram2_raw) = c("words", "total")
ngram2_raw
ngram3_total = rowSums(ngram3)
ngram3_raw = as.numeric(ngram3_total[1:nrow(ngram3)])
ngram3_raw = data.frame(names(ngram3_total),ngram3_raw)
names(ngram3_raw) = c("words", "total")
rm(test)
ngram3_raw
?split("I'm a cat")
split("I'm a cat")
?grep
gsub(" ","", "I'm a cat")
regexp(" ", "I'm a cat")
regexpr(" ", "I'm a cat")
grep(" ", "I'm a cat")
grepl(" ", "I'm a cat")
gregexpr(" ", "I'm a cat")
gregexpr(" ", "I'm a cat")[[1]]
gregexpr(" ", "I'm a cat")[[2]]
strsplit(" ", "I'm a cat")
strsplit("I'm a cat", " ")
length(strsplit("I'm a cat", " "))
ndim(strsplit("I'm a cat", " "))
dims(strsplit("I'm a cat", " "))
dim(strsplit("I'm a cat", " "))
(strsplit("I'm a cat", " ")[1])
(strsplit("I'm a cat", " ")[2])
?strsplit
unlist("I'm a cat")
(strsplit("I'm a cat", " ")[[1]])
(strsplit("I'm a cat", " ")[[2]])
as.data.frame(strsplit("I'm a cat", " "))
word = "I'm a cat"
words = as.data.frame(strsplit(word))
words = as.data.frame(strsplit(word, " "))
words
names(words) = "query"
words
ngram1_raw
word = "the cat"
words = as.data.frame(strsplit(word, " "))
names(words) = "query"
ngram2_raw
strsplit("cat man" , " ")
c("robot", "man")
c("robot", "man")[1]
c("robot", "man")[2]
strsplit("cat man" , " ")[1]
unlist(strsplit("cat man" , " "))
words = as.data.frame(unlist(strsplit(word, " ")))
words
names(words) = "query"
words
length(words)
ncol(words)
nrow(words)
library(snpStats)
library(broom)
data(for.exercise)
use <- seq(1, ncol(snps.10), 10)
sub.10 <- snps.10[,use]
snpdata = sub.10@.Data
status = subject.support$cc
install.packages("broom")
install.packages("snpStats")
library(snpStats)
library(broom)
data(for.exercise)
use <- seq(1, ncol(snps.10), 10)
sub.10 <- snps.10[,use]
snpdata = sub.10@.Data
status = subject.support$cc
install.packages("snpStats")
ngram2_raw
woo = unlist(strsplit(word, " "))
woo
woo[1]
woo[2]
?lapply
wow = unlist(strsplit(ngrma2_raw$word, " "))
wow = unlist(strsplit(ngram2_raw$word, " "))
wow = unlist(strsplit(ngram2_raw$words, " "))
names(ngram2_raw)
ncol(ngram2_raw)
nrow(ngram2_raw)
ngram2_raw$word1 = "dummy"
ngram2_raw$word2 = "dummy"
for(i in 1:nrow(ngram2_raw)){
ngram2_raw$word1[i] = unlist(strsplit(ngram2_raw$words[i], " "))[1]
ngram2_raw$word2[i] = unlist(strsplit(ngram2_raw$words[i], " "))[2]
}
ngram2_raw
unlist(strsplit(ngram2_raw$words[i], " "))[1]
unlist(strsplit(ngram2_raw$words[i,], " "))[1]
unlist(strsplit(ngram2_raw$words[i], " "))[1]
unlist(strsplit(ngram2_raw$words[1], " "))[1]
ngram2_raw$words[1]
unlist(strsplit(ngram2_raw$words[1], " "))
unlist(strsplit(ngramfor(i in 1:nrow(ngram2_raw)){
ngram2_raw$word1[i] = unlist(as.character(strsplit(ngram2_raw$words[i]), " "))[1]
ngram2_raw$word2[i] = unlist(as.character(strsplit(ngram2_raw$words[i]), " "))[2]
}2_raw$words[1], " "))
for(i in 1:nrow(ngram2_raw)){
ngram2_raw$word1[i] = unlist((strsplit(as.character(ngram2_raw$words[i])), " "))[1]
ngram2_raw$word2[i] = unlist(strsplit(as.character(ngram2_raw$words[i])), " "))[2]
}
for(i in 1:nrow(ngram2_raw)){
ngram2_raw$word1[i] = unlist(strsplit(as.character(ngram2_raw$words[i])), " ")[1]
ngram2_raw$word2[i] = unlist(strsplit(as.character(ngram2_raw$words[i])), " ")[2]
}
as.character(ngram2_raw$words[1])
for(i in 1:nrow(ngram2_raw)){
ngram2_raw$word1[i] = unlist(strsplit(as.character(ngram2_raw$words[i]), " "))[1]
ngram2_raw$word2[i] = unlist(strsplit(as.character(ngram2_raw$words[i]), " "))[2]
}
ngram2_raw
paste(c("dog", "cat"), " ")
paste0(c("dog", "cat"), " ")
?paste0
rm(woo)
paste(c("robo", "dog"), " ")
paste0(c("robo", "dog"), " ")
for(i in 1:nrow(ngram2_raw)){
split_words = unlist(strsplit(as.character(ngram3_raw$words[i]), " "))
print(paste0(split_words[1],split_words[2]))}
for(i in 1:nrow(ngram2_raw)){
split_words = unlist(strsplit(as.character(ngram3_raw$words[i]), " "))
print(paste(split_words[1],split_words[2], sep=" "))}
ngram3_raw$phrase = "dummy"
ngram3_raw$word3 = "dummy"
for(i in 1:nrow(ngram3_raw)){
split_words = unlist(strsplit(as.character(ngram3_raw$words[i]), " "))
ngram3_raw$phrase[i] = paste(split_words[1],split_words[2], sep=" ")
ngram3_raw$word3[i] = split_words[3]
}
ngram3_raw
ngram3_raw
ngram2_raw
you %in% nngram1_raw$word1
"you" %in% nngram1_raw$word1
"you" %in% ngram1_raw$word1
ngram1_raw$word1 %in% "you"
"you" %in% ngram1_raw$word1
is.character(ngram2_raw$word1)
is.character("you")
"you" %in% ngram1_raw$word1
"you" == ngram1_raw$word1
"you" %in% ngram1_raw$word2
"you" %in% ngram1_raw$words
save.image("~/GitHub/datasciencecoursera/Data Science Capstone/ng4.RData")
