}
else if(words[1,1] %in% ngram1_raw$words){
#predict 1gram freq vs freq of word in word2
w2 = as.data.frame(words[2,1])
if(nrow(ngram2_raw[ngram2_raw$word2 == as.vector(words[2,1]),]) >= 1){
prediction = paste(words[1,1], words[2,1])
}
else{
names(w2) = "query"
w2 = n1_pred(w2, word)
prediction = paste(words[1,1], w2)
}
}
else{ #Take highest occuring preceding word
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(ngram1_raw$words[which.max(ngram1_raw$total)]),]
if(words[2,1] %in% ngram2_raw$word2){ #Check if in dictionary
prediction = paste(word_match$word1[1],words[2,1])
}
else{ #Second word will be predicted based on highest occurence
prediction = as.vector(ngram2_raw$words[which.max(ngram2_raw$total)])
}
}
}
#Nice to have predict completely based on preceding characters
#could be improved by trying to do local alignment
if(query_length == 1){
prediction = n1_pred(words, word)
} else if(query_length == 2){
if(words[1,1] %in% ngram2_raw$word1){ #If first word there, take the highest occuring 2nd word following it
if(words[2,1] %in% ngram2_raw$word2){
prediction = paste(words[1,1],words[2,1])
}
else{
word_match = ngram2_raw[ngram2_raw$word1 == words[1,1],]
prediction = paste(words[1,1], as.vector(word_match$word2[which.max(word_match$total)]))
}
}
else if(words[1,1] %in% ngram1_raw$words){
#predict 1gram freq vs freq of word in word2
w2 = as.data.frame(words[2,1])
if(nrow(ngram2_raw[ngram2_raw$word2 == as.vector(words[2,1]),]) >= 1){
prediction = paste(words[1,1], words[2,1])
}
else{
names(w2) = "query"
w2 = n1_pred(w2, word)
prediction = paste(words[1,1], w2)
}
}
else{ #Take highest occuring preceding word
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(ngram1_raw$words[which.max(ngram1_raw$total)]),]
if(words[2,1] %in% ngram2_raw$word2){ #Check if in dictionary
prediction = paste(word_match$word1[1],words[2,1])
}
else{ #Second word will be predicted based on highest occurence
prediction = as.vector(ngram2_raw$words[which.max(ngram2_raw$total)])
}
}
}
shiny::runApp('shinyapp')
words[1,1]
ngram2_raw$word1 %in% words[1,1]
shiny::runApp('shinyapp')
if(query_length == 2){
if(words[1,1] %in% ngram2_raw$word1){ #If first word there, take the highest occuring 2nd word following it
if(words[2,1] %in% ngram2_raw$word2){
prediction = paste(words[1,1],words[2,1])
}
else{
word_match = ngram2_raw[ngram2_raw$word1 == words[1,1],]
prediction = paste(words[1,1], as.vector(word_match$word2[which.max(word_match$total)]))
}
}
else if(words[1,1] %in% ngram1_raw$words){
#predict 1gram freq vs freq of word in word2
w2 = as.data.frame(words[2,1])
if(nrow(ngram2_raw[ngram2_raw$word2 == as.vector(words[2,1]),]) >= 1){
prediction = paste(words[1,1], words[2,1])
}
else{
names(w2) = "query"
w2 = n1_pred(w2, word)
prediction = paste(words[1,1], w2)
}
}
else{ #Take highest occuring preceding word
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(ngram1_raw$words[which.max(ngram1_raw$total)]),]
if(words[2,1] %in% ngram2_raw$word2){ #Check if in dictionary
prediction = paste(word_match$word1[1],words[2,1])
}
else{ #Second word will be predicted based on highest occurence
prediction = as.vector(ngram2_raw$words[which.max(ngram2_raw$total)])
}
}
}
if(words[1,1] %in% ngram2_raw$word1){ #If first word there, take the highest occuring 2nd word following it
if(words[2,1] %in% ngram2_raw$word2){
prediction = paste(words[1,1],words[2,1])
}
else{
word_match = ngram2_raw[ngram2_raw$word1 == words[1,1],]
prediction = paste(words[1,1], as.vector(word_match$word2[which.max(word_match$total)]))
}
}
words[1,1] %in% ngram2_raw$word1
words[2,1] %in% ngram2_raw$word2
prediction = paste(words[1,1],words[2,1])
word_match = ngram2_raw[ngram2_raw$word1 == words[1,1],]
ngram2_raw[ngram2_raw$word1 == words[1,1],]
ngram2_raw[ngram2_raw$word1 == "th",]
words[1,1]
ngram2_raw[ngram2_raw$word1 == as.vector(words[1,1]),]
shiny::runApp('shinyapp')
as.vector(word_match$word2[which.max(word_match$total)])
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(words[1,1]),]
word_match
shiny::runApp('shinyapp')
shiny::runApp('shinyapp')
shiny::runApp('shinyapp')
word = "the state of"
words = as.data.frame(unlist(strsplit(word, " ")))
names(words) = "query"
query_length = nrow(words)
if(query_length == 3){
#check if first two words in, if not guess one from list
#check first two words and guess likelihood of next word based on prob
if(paste(words[1,1], words[2,1]) %in% ngram3_raw$phrase){
if(words[3,1] %in% ngram3_raw$word3){
prediction = paste(paste(words[1,1], words[2,1]), words[3,1])
} else{
word_match = ngram3_raw[ngram3_raw$phrase == paste(words[1,1], words[2,1]),]
prediction = paste(paste(words[1,1], words[2,1]), as.vector(word_match$word3[which.max(word_match$total)]))
}
} else{ #Take highest occuring phrase
if(paste(words[1,1], words[2,1]) %in% ngram2_raw$words){
w3 = as.data.frame(words[3,1])
names(w3) = "query"
w3 = n1_pred(w3, word)
predction = paste(words[1,1], words[2,1], w3)
} else{
word_match = ngram3_raw[ngram3_raw$phrase == as.vector(ngram2_raw$words[which.max(ngram2_raw$total)]),]
if(words[3,1] %in% ngram3_raw$word3){ #Check if in dictionary
prediction = paste(word_match$phrase[1], words[2,1])
} else{ #Second word will be predicted based on highest occurence
prediction = paste(word_match$phrase[1], as.vector(word_match$word3[which.max(word_match$total)]))
}
}
}
}
prediction
paste(words[1,1], words[2,1]
)
paste(words[1,1], words[2,1]) %in% ngram2_raw$words
w3 = as.data.frame(words[3,1])
w3
names(w3) = "query"
w3
w3 = n1_pred(w3, word)
w3
predction = paste(words[1,1], words[2,1], w3)
prediction
paste(words[1,1], words[2,1]
)
paste(words[1,1])
paste(words[1,1], words[2,1])
w3
?paste
predction = paste(words[1,1], words[2,1], w3)
w3
prediction
paste(words[1,1], words[2,1], w3)
shiny::runApp('shinyapp')
shiny::runApp('shinyapp')
shiny::runApp('shinyapp')
ngram1_raw = read.csv("data/ng1.csv")
ngram2_raw = read.csv("data/ng2.csv")
ngram3_raw = read.csv("data/ng3.csv")
ngram1_raw = read.csv("shinyapp/data/ng1.csv")
ngram2_raw = read.csv("shinyapp/data/ng2.csv")
ngram3_raw = read.csv("shinyapp/data/ng3.csv")
library(shiny)
shiny::runApp('shinyapp')
word = "i am here"
words = as.data.frame(unlist(strsplit(word, " ")))
names(words) = "query"
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(words[2,1])]
word_match
ngram2_raw[ngram2_raw$word1 == as.vector(words[2,1]),]
words[2,1]
word = "are you here"
words = as.data.frame(unlist(strsplit(word, " ")))
names(words) = "query"
ngram2_raw[ngram2_raw$word1 == as.vector(words[2,1]),]
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(words[2,1])]
words[2,1]
as.vector(words[2,1])
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(words[2,1]),]
word_match
as.vector(word_match$word2[which.max(word_match$total)])
shiny::runApp('shinyapp')
shiny::runApp('shinyapp')
shiny::runApp('shinyapp')
shiny::runApp('shinyapp')
#Predicts word/word phrases
pred_word = function(word){
words = as.data.frame(unlist(strsplit(word, " ")))
names(words) = "query"
query_length = nrow(words)
#Nice to have predict completely based on preceding characters
#could be improved by trying to do local alignment
if(query_length == 1){
prediction = n1_pred(words, word)
} else if(query_length == 2){
if(words[1,1] %in% ngram2_raw$word1){ #If first word there, take the highest occuring 2nd word following it
if(words[2,1] %in% ngram2_raw$word2){
prediction = paste(words[1,1],words[2,1])
} else{
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(words[1,1]),]
prediction = paste(words[1,1], as.vector(word_match$word2[which.max(word_match$total)]))
}
} else if(words[1,1] %in% ngram1_raw$words){
#predict 1gram freq vs freq of word in word2
w2 = as.data.frame(words[2,1])
if(nrow(ngram2_raw[ngram2_raw$word2 == as.vector(words[2,1]),]) >= 1){
prediction = paste(words[1,1], words[2,1])
} else{
names(w2) = "query"
w2 = n1_pred(w2, word)
prediction = paste(words[1,1], w2)
}
}else{ #Take highest occuring preceding word
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(ngram1_raw$words[which.max(ngram1_raw$total)]),]
if(words[2,1] %in% ngram2_raw$word2){ #Check if in dictionary
prediction = paste(word_match$word1[1],words[2,1])
} else{ #Second word will be predicted based on highest occurence
prediction = as.vector(ngram2_raw$words[which.max(ngram2_raw$total)])
}
}
} else if(query_length == 3){
#check if first two words in, if not guess one from list
#check first two words and guess likelihood of next word based on prob
if(paste(words[1,1], words[2,1]) %in% ngram3_raw$phrase){
if(words[3,1] %in% ngram3_raw$word3){
prediction = word
} else if(words[2,1] %in% ngram2_raw$word1){
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(words[2,1]),]
prediction = paste(words[1,1], as.vector(word_match$words[which.max(word_match$total)]))
} else {
word_match = ngram3_raw[ngram3_raw$phrase == paste(words[1,1], words[2,1]),]
prediction = paste(paste(words[1,1], words[2,1]), as.vector(word_match$word3[which.max(word_match$total)]))
}
} else{
if(paste(words[1,1], words[2,1]) %in% ngram2_raw$words){ #takes phrase from 2gram if there
w3 = as.data.frame(words[3,1])
names(w3) = "query"
w3 = n1_pred(w3, word)
prediction = paste(words[1,1], words[2,1], w3)
} else if(paste(words[2,1], words[3,1]) %in% ngram2_raw$words){ #checks end phrase
w3 = as.data.frame(words[1,1])
names(w3) = "query"
w3 = n1_pred(w3, word)
prediction = paste(w3, words[2,1], words[3,1] )
} else{ #takes highest occuring phrase from ngram3
word_match = ngram3_raw[ngram3_raw$phrase == as.vector(ngram2_raw$words[which.max(ngram2_raw$total)]),]
if(words[3,1] %in% ngram3_raw$word3){ #Check if in dictionary
prediction = paste(word_match$phrase[1], words[2,1])
} else{ #Second word will be predicted based on highest occurence
prediction = paste(word_match$phrase[1], as.vector(word_match$word3[which.max(word_match$total)]))
}
}
}
} else{
prediction = "Please limit prediction to 3 words max"
}
return(prediction)
}
#Predicts 1gram
n1_pred = function(words, word){
if(words$query %in% ngram1_raw$words){ #If word in dict, then it is correct
prediction = word
}
else if(substr(words$query[1],1,1) %in% ngram1_raw$start){ #Takes the highest occuring same starting char
start_test = substr(words$query[1],1,1)
start_match = ngram1_raw[ngram1_raw$start == start_test,]
prediction = as.vector(start_match$words[which.max(start_match$total)])
}
else{ #Take the highest occuring word, be great if this took it based on local alignment although be less of issue if bigger data size
prediction = as.vector(ngram1_raw$words[which.max(ngram1_raw$total)])
}
return(prediction)
}
word = "here i am"
pred_word(word)
#Predicts word/word phrases
pred_word = function(word){
words = as.data.frame(unlist(strsplit(word, " ")))
names(words) = "query"
query_length = nrow(words)
#Nice to have predict completely based on preceding characters
#could be improved by trying to do local alignment
if(query_length == 1){
prediction = n1_pred(words, word)
} else if(query_length == 2){
if(words[1,1] %in% ngram2_raw$word1){ #If first word there, take the highest occuring 2nd word following it
if(words[2,1] %in% ngram2_raw$word2){
prediction = paste(words[1,1],words[2,1])
} else{
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(words[1,1]),]
prediction = paste(words[1,1], as.vector(word_match$word2[which.max(word_match$total)]))
}
} else if(words[1,1] %in% ngram1_raw$words){
#predict 1gram freq vs freq of word in word2
w2 = as.data.frame(words[2,1])
if(nrow(ngram2_raw[ngram2_raw$word2 == as.vector(words[2,1]),]) >= 1){
prediction = paste(words[1,1], words[2,1])
} else{
names(w2) = "query"
w2 = n1_pred(w2, word)
prediction = paste(words[1,1], w2)
}
}else{ #Take highest occuring preceding word
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(ngram1_raw$words[which.max(ngram1_raw$total)]),]
if(words[2,1] %in% ngram2_raw$word2){ #Check if in dictionary
prediction = paste(word_match$word1[1],words[2,1])
} else{ #Second word will be predicted based on highest occurence
prediction = as.vector(ngram2_raw$words[which.max(ngram2_raw$total)])
}
}
} else if(query_length == 3){
#check if first two words in, if not guess one from list
#check first two words and guess likelihood of next word based on prob
if(paste(words[1,1], words[2,1]) %in% ngram3_raw$phrase){
if(words[3,1] %in% ngram3_raw$word3){
prediction = word
} else if(words[2,1] %in% ngram2_raw$word1){
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(words[2,1]),]
prediction = paste(words[1,1], as.vector(word_match$words[which.max(word_match$total)]))
print("what")
} else {
word_match = ngram3_raw[ngram3_raw$phrase == paste(words[1,1], words[2,1]),]
prediction = paste(paste(words[1,1], words[2,1]), as.vector(word_match$word3[which.max(word_match$total)]))
print("wow")
}
} else{
if(paste(words[1,1], words[2,1]) %in% ngram2_raw$words){ #takes phrase from 2gram if there
w3 = as.data.frame(words[3,1])
names(w3) = "query"
w3 = n1_pred(w3, word)
prediction = paste(words[1,1], words[2,1], w3)
} else if(paste(words[2,1], words[3,1]) %in% ngram2_raw$words){ #checks end phrase
w3 = as.data.frame(words[1,1])
names(w3) = "query"
w3 = n1_pred(w3, word)
prediction = paste(w3, words[2,1], words[3,1] )
} else{ #takes highest occuring phrase from ngram3
word_match = ngram3_raw[ngram3_raw$phrase == as.vector(ngram2_raw$words[which.max(ngram2_raw$total)]),]
if(words[3,1] %in% ngram3_raw$word3){ #Check if in dictionary
prediction = paste(word_match$phrase[1], words[2,1])
} else{ #Second word will be predicted based on highest occurence
prediction = paste(word_match$phrase[1], as.vector(word_match$word3[which.max(word_match$total)]))
}
}
}
} else{
prediction = "Please limit prediction to 3 words max"
}
return(prediction)
}
pred_word(word)
shiny::runApp('shinyapp')
?count
table(ngram2_raw$word2)
table(ngram2_raw$word2)[1]
table(ngram2_raw$word2)[1[1]]
table(ngram2_raw$word2)[1]
as.numeri(table(ngram2_raw$word2)[1])
as.numeric(table(ngram2_raw$word2)[1])
max(table(ngram2_raw$word2))
shiny::runApp('shinyapp')
word = "here there"
words = as.data.frame(unlist(strsplit(word, " ")))
names(words) = "query"
if(query_length == 2){
if(words[1,1] %in% ngram2_raw$word1){ #If first word there, take the highest occuring 2nd word following it
if(words[2,1] %in% ngram2_raw$word2){
prediction = paste(words[1,1],words[2,1])
} else{
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(words[1,1]),]
prediction = paste(words[1,1], as.vector(word_match$word2[which.max(word_match$total)]))
}
} else if(words[1,1] %in% ngram1_raw$words){
#predict 1gram freq vs freq of word in word2
w2 = as.data.frame(words[2,1])
if(nrow(ngram2_raw[ngram2_raw$word2 == as.vector(words[2,1]),]) >= 1){
prediction = paste(words[1,1], words[2,1])
} else{
names(w2) = "query"
w2 = n1_pred(w2, word)
prediction = paste(words[1,1], w2)
}
}else{ #Take highest occuring preceding word
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(ngram1_raw$words[which.max(ngram1_raw$total)]),]
if(words[2,1] %in% ngram2_raw$word2){ #Check if in dictionary
prediction = paste(word_match$word1[1],words[2,1])
} else{ #Second word will be predicted based on highest occurence
prediction = as.vector(ngram2_raw$words[which.max(ngram2_raw$total)])
}
}
}
query_length = nrow(words)
if(query_length == 2){
if(words[1,1] %in% ngram2_raw$word1){ #If first word there, take the highest occuring 2nd word following it
if(words[2,1] %in% ngram2_raw$word2){
prediction = paste(words[1,1],words[2,1])
} else{
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(words[1,1]),]
prediction = paste(words[1,1], as.vector(word_match$word2[which.max(word_match$total)]))
}
} else if(words[1,1] %in% ngram1_raw$words){
#predict 1gram freq vs freq of word in word2
w2 = as.data.frame(words[2,1])
if(nrow(ngram2_raw[ngram2_raw$word2 == as.vector(words[2,1]),]) >= 1){
prediction = paste(words[1,1], words[2,1])
} else{
names(w2) = "query"
w2 = n1_pred(w2, word)
prediction = paste(words[1,1], w2)
}
}else{ #Take highest occuring preceding word
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(ngram1_raw$words[which.max(ngram1_raw$total)]),]
if(words[2,1] %in% ngram2_raw$word2){ #Check if in dictionary
prediction = paste(word_match$word1[1],words[2,1])
} else{ #Second word will be predicted based on highest occurence
prediction = as.vector(ngram2_raw$words[which.max(ngram2_raw$total)])
}
}
}
predction
prediction
prediction = paste(words[1,1],words[2,1])
prediction
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(words[1,1]),]
prediction = paste(words[1,1], as.vector(word_match$word2[which.max(word_match$total)]))
prediction
prediction = paste(words[1,1], words[2,1])
prediction
w2 = as.data.frame(words[2,1])
names(w2) = "query"
w2 = n1_pred(w2, word)
prediction = paste(words[1,1], w2)
prediction
word
w2
w2 = as.data.frame(words[2,1])
w2
n1_pred(w2,word)
w2
names(w2) = "query"
n1_pred(w2,word)
w2 = n1_pred(w2, word)
w2
shiny::runApp('shinyapp')
prediction = paste(words[1,1], w2)
prediction
w2
w2 = as.data.frame(words[2,1])
names(w2) = "query"
w2 = n1_pred(w2, word)
w2
w2 = as.data.frame(words[2,1])
w2
names(w2) = "query"
w2 = n1_pred(w2, as.vector(words[2,1]))
prediction = paste(words[1,1], w2)
shiny::runApp('shinyapp')
shiny::runApp('shinyapp')
table(ngram2_raw$word2)
which.max(table(ngram2_raw$word2))
as.vector(which.max(table(ngram2_raw$word2)))
as.character(which.max(table(ngram2_raw$word2)))
names(which.max(table(ngram2_raw$word2)))
table(ngram2_raw$word2) < (which.max(table(ngram2_raw$word2)))
freqs = table(ngram2_raw$word2)
freqs
prediction = paste(paste(words[1,1], words[2,1]), names(which.max(table(ngram2_raw$word2))))
prediction
word
order(freqs)
freqs[order(freqs)]
freqs[order(freqs)][:-1]
freqs[order(freqs)][-1:]
freqs[order(freqs)][-1]
freqs[order(freqs)]
length(freqs[order(freqs)])
freqs[order(freqs)][85]
freqs[order(freqs)][84]
prediction = paste(paste(words[1,1], words[2,1]), names(freqs[order(freqs)][len_freqs - 1]))
len_freqs = length(freqs)
prediction = paste(paste(words[1,1], words[2,1]), names(freqs[order(freqs)][len_freqs - 1]))
prediction
shiny::runApp('shinyapp')
model_pres
install.packages(c("digest", "rJava"))
install.packages("knitr")
install.packages("knitr")
shiny::runApp('shinyapp')
Model Performance
========================================================
The model in action
ftft
## Preprocessing
Datasets from twitter, blogs and news are used. They are processed to remove extra spaces, swears, and punctuation. The text is then further processed to 1grams, 2grams, and 3grams.
