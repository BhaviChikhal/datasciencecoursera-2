}
else if(query_length == 2){
if(words[1,1] %in% ngram2_raw$word1){ #If first word there, take the highest occuring 2nd word following it
if(words[2,1] %in% ngram2_raw$word2){
prediction = words[2,1]
}
else{
word_match = ngram2_raw[ngram2_raw$word1 == words[1,1],]
prediction = as.vector(word_match$word2[which.max(word_match$total)])
}
}
else{ #Take highest occuring preceding word
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(ngram1_raw$words[which.max(ngram1_raw$total)]),]
if(words[2,1] %in% ngram2_raw$word2){ #Check if in dictionary
prediction = words[2,1]
}
else{ #Second word will be predicted based on highest occurence
prediction = as.vector(ngram2_raw$words[which.max(ngram2_raw$total)])
}
}
}
else if(query_length == 3){
#check if first two words in, if not guess one from list
#check first two words and guess likelihood of next word based on prob
if(paste(words[1,1], words[2,1]) %in% ngram3_raw$phrase){
if(words[3,1] %in% ngram3_raw$word3){
prediction = words[3,1]
}
else{
word_match = ngram3_raw[ngram3_raw$phrase == paste(words[1,1], words[2,1]),]
prediction = as.vector(word_match$word3[which.max(word_match$total)])
}
}
else{ #Take highest occuring phrase
word_match = ngram3_raw[ngram3_raw$phrase == as.vector(ngram2_raw$words[which.max(ngram2_raw$total)]),]
if(words[3,1] %in% ngram3_raw$word3){ #Check if in dictionary
prediction = words[2,1]
}
else{ #Second word will be predicted based on highest occurence
prediction = paste(word_match$phrase[1], as.vector(word_match$word3[which.max(word_match$total)]))
}
}
}
else{
prediction = "Please limit prediction to 3 works max"
}
return(prediction)
}
pred_word(word)
#Prediction function for n-1(2-3 words total)
pred_word = function(word){
words = as.data.frame(unlist(strsplit(word, " ")))
names(words) = "query"
query_length = nrow(words)
#Nice to have predict completely based on preceding characters
#could be improved by trying to do local alignment
if(query_length == 1){
if(words$query %in% ngram1_raw$words){ #If word in dict, then it is correct
prediction = words[1,1]
}
else if(substr(words$query[1],1,1) %in% ngram1_raw$start){ #Takes the highest occuring same starting char
start_test = substr(words$query[1],1,1)
start_match = ngram1_raw[ngram1_raw$start == start_test,]
prediction = as.vector(start_match$words[which.max(start_match$total)])
}
else{ #Take the highest occuring word, be great if this took it based on local alignment although be less of issue if bigger data size
prediction = as.vector(ngram1_raw$words[which.max(ngram1_raw$total)])
}
}
else if(query_length == 2){
if(words[1,1] %in% ngram2_raw$word1){ #If first word there, take the highest occuring 2nd word following it
if(words[2,1] %in% ngram2_raw$word2){
prediction = words[2,1]
}
else{
word_match = ngram2_raw[ngram2_raw$word1 == words[1,1],]
prediction = as.vector(word_match$word2[which.max(word_match$total)])
}
}
else{ #Take highest occuring preceding word
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(ngram1_raw$words[which.max(ngram1_raw$total)]),]
if(words[2,1] %in% ngram2_raw$word2){ #Check if in dictionary
prediction = words[2,1]
}
else{ #Second word will be predicted based on highest occurence
prediction = as.vector(ngram2_raw$words[which.max(ngram2_raw$total)])
}
}
}
else if(query_length == 3){
#check if first two words in, if not guess one from list
#check first two words and guess likelihood of next word based on prob
if(paste(words[1,1], words[2,1]) %in% ngram3_raw$phrase){
if(words[3,1] %in% ngram3_raw$word3){
prediction = paste(paste(words[1,1], words[2,1]), words[3,1])
}
else{
word_match = ngram3_raw[ngram3_raw$phrase == paste(words[1,1], words[2,1]),]
prediction = paste(paste(words[1,1], words[2,1]), as.vector(word_match$word3[which.max(word_match$total)]))
}
}
else{ #Take highest occuring phrase
word_match = ngram3_raw[ngram3_raw$phrase == as.vector(ngram2_raw$words[which.max(ngram2_raw$total)]),]
if(words[3,1] %in% ngram3_raw$word3){ #Check if in dictionary
prediction = paste(word_match$phrase[1], words[2,1])
}
else{ #Second word will be predicted based on highest occurence
prediction = paste(word_match$phrase[1], as.vector(word_match$word3[which.max(word_match$total)]))
}
}
}
else{
prediction = "Please limit prediction to 3 works max"
}
return(prediction)
}
pred_word(word)
word
ngram3_raw
word = "you want cat"
#Prediction function for n-1(2-3 words total)
pred_word = function(word){
words = as.data.frame(unlist(strsplit(word, " ")))
names(words) = "query"
query_length = nrow(words)
#Nice to have predict completely based on preceding characters
#could be improved by trying to do local alignment
if(query_length == 1){
if(words$query %in% ngram1_raw$words){ #If word in dict, then it is correct
prediction = words[1,1]
}
else if(substr(words$query[1],1,1) %in% ngram1_raw$start){ #Takes the highest occuring same starting char
start_test = substr(words$query[1],1,1)
start_match = ngram1_raw[ngram1_raw$start == start_test,]
prediction = as.vector(start_match$words[which.max(start_match$total)])
}
else{ #Take the highest occuring word, be great if this took it based on local alignment although be less of issue if bigger data size
prediction = as.vector(ngram1_raw$words[which.max(ngram1_raw$total)])
}
}
else if(query_length == 2){
if(words[1,1] %in% ngram2_raw$word1){ #If first word there, take the highest occuring 2nd word following it
if(words[2,1] %in% ngram2_raw$word2){
prediction = words[2,1]
}
else{
word_match = ngram2_raw[ngram2_raw$word1 == words[1,1],]
prediction = as.vector(word_match$word2[which.max(word_match$total)])
}
}
else{ #Take highest occuring preceding word
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(ngram1_raw$words[which.max(ngram1_raw$total)]),]
if(words[2,1] %in% ngram2_raw$word2){ #Check if in dictionary
prediction = words[2,1]
}
else{ #Second word will be predicted based on highest occurence
prediction = as.vector(ngram2_raw$words[which.max(ngram2_raw$total)])
}
}
}
else if(query_length == 3){
#check if first two words in, if not guess one from list
#check first two words and guess likelihood of next word based on prob
if(paste(words[1,1], words[2,1]) %in% ngram3_raw$phrase){
if(words[3,1] %in% ngram3_raw$word3){
prediction = paste(paste(words[1,1], words[2,1]), words[3,1])
}
else{
word_match = ngram3_raw[ngram3_raw$phrase == paste(words[1,1], words[2,1]),]
prediction = paste(paste(words[1,1], words[2,1]), as.vector(word_match$word3[which.max(word_match$total)]))
}
}
else{ #Take highest occuring phrase
word_match = ngram3_raw[ngram3_raw$phrase == as.vector(ngram2_raw$words[which.max(ngram2_raw$total)]),]
if(words[3,1] %in% ngram3_raw$word3){ #Check if in dictionary
prediction = paste(word_match$phrase[1], words[2,1])
}
else{ #Second word will be predicted based on highest occurence
prediction = paste(word_match$phrase[1], as.vector(word_match$word3[which.max(word_match$total)]))
}
}
}
else{
prediction = "Please limit prediction to 3 works max"
}
return(prediction)
}
pred_word(word)
word = "dog man"
#Prediction function for n-1(2-3 words total)
pred_word = function(word){
words = as.data.frame(unlist(strsplit(word, " ")))
names(words) = "query"
query_length = nrow(words)
#Nice to have predict completely based on preceding characters
#could be improved by trying to do local alignment
if(query_length == 1){
if(words$query %in% ngram1_raw$words){ #If word in dict, then it is correct
prediction = words[1,1]
}
else if(substr(words$query[1],1,1) %in% ngram1_raw$start){ #Takes the highest occuring same starting char
start_test = substr(words$query[1],1,1)
start_match = ngram1_raw[ngram1_raw$start == start_test,]
prediction = as.vector(start_match$words[which.max(start_match$total)])
}
else{ #Take the highest occuring word, be great if this took it based on local alignment although be less of issue if bigger data size
prediction = as.vector(ngram1_raw$words[which.max(ngram1_raw$total)])
}
}
else if(query_length == 2){
if(words[1,1] %in% ngram2_raw$word1){ #If first word there, take the highest occuring 2nd word following it
if(words[2,1] %in% ngram2_raw$word2){
prediction = words[2,1]
}
else{
word_match = ngram2_raw[ngram2_raw$word1 == words[1,1],]
prediction = as.vector(word_match$word2[which.max(word_match$total)])
}
}
else{ #Take highest occuring preceding word
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(ngram1_raw$words[which.max(ngram1_raw$total)]),]
if(words[2,1] %in% ngram2_raw$word2){ #Check if in dictionary
prediction = words[2,1]
}
else{ #Second word will be predicted based on highest occurence
prediction = paste(word_match$word1[1],as.vector(ngram2_raw$words[which.max(ngram2_raw$total)]))
}
}
}
else if(query_length == 3){
#check if first two words in, if not guess one from list
#check first two words and guess likelihood of next word based on prob
if(paste(words[1,1], words[2,1]) %in% ngram3_raw$phrase){
if(words[3,1] %in% ngram3_raw$word3){
prediction = paste(paste(words[1,1], words[2,1]), words[3,1])
}
else{
word_match = ngram3_raw[ngram3_raw$phrase == paste(words[1,1], words[2,1]),]
prediction = paste(paste(words[1,1], words[2,1]), as.vector(word_match$word3[which.max(word_match$total)]))
}
}
else{ #Take highest occuring phrase
word_match = ngram3_raw[ngram3_raw$phrase == as.vector(ngram2_raw$words[which.max(ngram2_raw$total)]),]
if(words[3,1] %in% ngram3_raw$word3){ #Check if in dictionary
prediction = paste(word_match$phrase[1], words[2,1])
}
else{ #Second word will be predicted based on highest occurence
prediction = paste(word_match$phrase[1], as.vector(word_match$word3[which.max(word_match$total)]))
}
}
}
else{
prediction = "Please limit prediction to 3 works max"
}
return(prediction)
}
pred_word(word)
wprd
word
words = as.data.frame(unlist(strsplit(word, " ")))
names(words) = "query"
words
words = as.data.frame(unlist(strsplit(word, " ")))
names(words) = "query"
#Prediction function for n-1(2-3 words total)
pred_word = function(word){
words = as.data.frame(unlist(strsplit(word, " ")))
names(words) = "query"
query_length = nrow(words)
#Nice to have predict completely based on preceding characters
#could be improved by trying to do local alignment
if(query_length == 1){
if(words$query %in% ngram1_raw$words){ #If word in dict, then it is correct
prediction = words[1,1]
}
else if(substr(words$query[1],1,1) %in% ngram1_raw$start){ #Takes the highest occuring same starting char
start_test = substr(words$query[1],1,1)
start_match = ngram1_raw[ngram1_raw$start == start_test,]
prediction = as.vector(start_match$words[which.max(start_match$total)])
}
else{ #Take the highest occuring word, be great if this took it based on local alignment although be less of issue if bigger data size
prediction = as.vector(ngram1_raw$words[which.max(ngram1_raw$total)])
}
}
else if(query_length == 2){
if(words[1,1] %in% ngram2_raw$word1){ #If first word there, take the highest occuring 2nd word following it
if(words[2,1] %in% ngram2_raw$word2){
prediction = words[2,1]
}
else{
word_match = ngram2_raw[ngram2_raw$word1 == words[1,1],]
prediction = as.vector(word_match$word2[which.max(word_match$total)])
}
}
else{ #Take highest occuring preceding word
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(ngram1_raw$words[which.max(ngram1_raw$total)]),]
if(words[2,1] %in% ngram2_raw$word2){ #Check if in dictionary
prediction = words[2,1]
}
else{ #Second word will be predicted based on highest occurence
prediction = paste(word_match$word1[1],as.vector(ngram2_raw$words[which.max(ngram2_raw$total)]))
}
}
}
else if(query_length == 3){
#check if first two words in, if not guess one from list
#check first two words and guess likelihood of next word based on prob
if(paste(words[1,1], words[2,1]) %in% ngram3_raw$phrase){
if(words[3,1] %in% ngram3_raw$word3){
prediction = paste(paste(words[1,1], words[2,1]), words[3,1])
}
else{
word_match = ngram3_raw[ngram3_raw$phrase == paste(words[1,1], words[2,1]),]
prediction = paste(paste(words[1,1], words[2,1]), as.vector(word_match$word3[which.max(word_match$total)]))
}
}
else{ #Take highest occuring phrase
word_match = ngram3_raw[ngram3_raw$phrase == as.vector(ngram2_raw$words[which.max(ngram2_raw$total)]),]
if(words[3,1] %in% ngram3_raw$word3){ #Check if in dictionary
prediction = paste(word_match$phrase[1], words[2,1])
}
else{ #Second word will be predicted based on highest occurence
prediction = paste(word_match$phrase[1], as.vector(word_match$word3[which.max(word_match$total)]))
}
}
}
else{
prediction = "Please limit prediction to 3 works max"
}
return(prediction)
}
pred_word(word)
word
query_length = nrow(words)
query_length
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(ngram1_raw$words[which.max(ngram1_raw$total)]),]
word_match
word_match$word1[1]
prediction = paste(word_match$word1[1],as.vector(ngram2_raw$words[which.max(ngram2_raw$total)]))
prediction
prediction = paste(word_match$word1[1],words[2,1])
prediction
#Prediction function for n-1(2-3 words total)
pred_word = function(word){
words = as.data.frame(unlist(strsplit(word, " ")))
names(words) = "query"
query_length = nrow(words)
#Nice to have predict completely based on preceding characters
#could be improved by trying to do local alignment
if(query_length == 1){
if(words$query %in% ngram1_raw$words){ #If word in dict, then it is correct
prediction = words[1,1]
}
else if(substr(words$query[1],1,1) %in% ngram1_raw$start){ #Takes the highest occuring same starting char
start_test = substr(words$query[1],1,1)
start_match = ngram1_raw[ngram1_raw$start == start_test,]
prediction = as.vector(start_match$words[which.max(start_match$total)])
}
else{ #Take the highest occuring word, be great if this took it based on local alignment although be less of issue if bigger data size
prediction = as.vector(ngram1_raw$words[which.max(ngram1_raw$total)])
}
}
else if(query_length == 2){
if(words[1,1] %in% ngram2_raw$word1){ #If first word there, take the highest occuring 2nd word following it
if(words[2,1] %in% ngram2_raw$word2){
prediction = words[2,1]
}
else{
word_match = ngram2_raw[ngram2_raw$word1 == words[1,1],]
prediction = as.vector(word_match$word2[which.max(word_match$total)])
}
}
else{ #Take highest occuring preceding word
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(ngram1_raw$words[which.max(ngram1_raw$total)]),]
if(words[2,1] %in% ngram2_raw$word2){ #Check if in dictionary
prediction = paste(word_match$word1[1],words[2,1])
}
else{ #Second word will be predicted based on highest occurence
prediction = as.vector(ngram2_raw$words[which.max(ngram2_raw$total)])
}
}
}
else if(query_length == 3){
#check if first two words in, if not guess one from list
#check first two words and guess likelihood of next word based on prob
if(paste(words[1,1], words[2,1]) %in% ngram3_raw$phrase){
if(words[3,1] %in% ngram3_raw$word3){
prediction = paste(paste(words[1,1], words[2,1]), words[3,1])
}
else{
word_match = ngram3_raw[ngram3_raw$phrase == paste(words[1,1], words[2,1]),]
prediction = paste(paste(words[1,1], words[2,1]), as.vector(word_match$word3[which.max(word_match$total)]))
}
}
else{ #Take highest occuring phrase
word_match = ngram3_raw[ngram3_raw$phrase == as.vector(ngram2_raw$words[which.max(ngram2_raw$total)]),]
if(words[3,1] %in% ngram3_raw$word3){ #Check if in dictionary
prediction = paste(word_match$phrase[1], words[2,1])
}
else{ #Second word will be predicted based on highest occurence
prediction = paste(word_match$phrase[1], as.vector(word_match$word3[which.max(word_match$total)]))
}
}
}
else{
prediction = "Please limit prediction to 3 works max"
}
return(prediction)
}
pred_word(word)
save.image("~/GitHub/datasciencecoursera/Data Science Capstone/ng5.RData")
library(shiny)
runApp("~/shinyapp")
install.packages("shiny")
> library(shiny)
> runApp("~/shinyapp")
library(shiny)
runApp("~/shinyapp")
library(shiny)
runApp("/shinyapp")
getwd()
runApp("shinyapp")
runApp("shinyapp")
runApp("shinyapp")
library(shiny)
shinyapp()
getwd()
dir()
runApp("shinyapp")
word = "i am h"
pred_word(word)
#Prediction function for n-1(2-3 words total)
pred_word = function(word){
words = as.data.frame(unlist(strsplit(word, " ")))
names(words) = "query"
query_length = nrow(words)
#Nice to have predict completely based on preceding characters
#could be improved by trying to do local alignment
if(query_length == 1){
if(words$query %in% ngram1_raw$words){ #If word in dict, then it is correct
prediction = words[1,1]
}
else if(substr(words$query[1],1,1) %in% ngram1_raw$start){ #Takes the highest occuring same starting char
start_test = substr(words$query[1],1,1)
start_match = ngram1_raw[ngram1_raw$start == start_test,]
prediction = as.vector(start_match$words[which.max(start_match$total)])
}
else{ #Take the highest occuring word, be great if this took it based on local alignment although be less of issue if bigger data size
prediction = as.vector(ngram1_raw$words[which.max(ngram1_raw$total)])
}
}
else if(query_length == 2){
if(words[1,1] %in% ngram2_raw$word1){ #If first word there, take the highest occuring 2nd word following it
if(words[2,1] %in% ngram2_raw$word2){
prediction = paste(words[1,1],words[2,1])
}
else{
word_match = ngram2_raw[ngram2_raw$word1 == words[1,1],]
prediction = paste(words[1,1], as.vector(word_match$word2[which.max(word_match$total)]))
}
}
else{ #Take highest occuring preceding word
word_match = ngram2_raw[ngram2_raw$word1 == as.vector(ngram1_raw$words[which.max(ngram1_raw$total)]),]
if(words[2,1] %in% ngram2_raw$word2){ #Check if in dictionary
prediction = paste(word_match$word1[1],words[2,1])
}
else{ #Second word will be predicted based on highest occurence
prediction = as.vector(ngram2_raw$words[which.max(ngram2_raw$total)])
}
}
}
else if(query_length == 3){
#check if first two words in, if not guess one from list
#check first two words and guess likelihood of next word based on prob
if(paste(words[1,1], words[2,1]) %in% ngram3_raw$phrase){
if(words[3,1] %in% ngram3_raw$word3){
prediction = paste(paste(words[1,1], words[2,1]), words[3,1])
}
else{
word_match = ngram3_raw[ngram3_raw$phrase == paste(words[1,1], words[2,1]),]
prediction = paste(paste(words[1,1], words[2,1]), as.vector(word_match$word3[which.max(word_match$total)]))
}
}
else{ #Take highest occuring phrase
word_match = ngram3_raw[ngram3_raw$phrase == as.vector(ngram2_raw$words[which.max(ngram2_raw$total)]),]
if(words[3,1] %in% ngram3_raw$word3){ #Check if in dictionary
prediction = paste(word_match$phrase[1], words[2,1])
}
else{ #Second word will be predicted based on highest occurence
prediction = paste(word_match$phrase[1], as.vector(word_match$word3[which.max(word_match$total)]))
}
}
}
else{
prediction = "Please limit prediction to 3 works max"
}
return(prediction)
}
pred_word(word)
ngram3_total
write.csv(ngram1_total, "ng1.csv")
write.csv(ngram1_raw, "ng1.csv")
write.csv(ngram2_raw, "ng2.csv")
write.csv(ngram3_raw, "ng3.csv")
shiny::runApp('shinyapp')
shiny::runApp('shinyapp')
shiny::runApp('shinyapp')
shiny::runApp('shinyapp')
shiny::runApp('shinyapp')
shiny::runApp('shinyapp')
shiny::runApp('shinyapp')
shiny::runApp('shinyapp')
